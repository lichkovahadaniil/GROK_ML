{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f90bac",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c5b2d",
   "metadata": {},
   "source": [
    "<img src=\".././photo/condition4.png\" alt=\"photo\" width=\"672\" height=\"336\">\n",
    "<img src=\".././photo/condition5.png\" alt=\"photo\" width=\"672\" height=\"336\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bdd216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4323446928853572\n",
      "1.8143849337851594\n",
      "[-1.55870287 -0.77127223  0.28664769  0.8162054  -0.14011833]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.5 * x**2 - 0.1 * 1/np.exp(-x) + 0.5 * np.cos(2*x) - 2.\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения по оси абсцисс [-5; 5] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "x_train = [[1, x, x**2, np.cos(2*x), np.sin(2*x)] for x in coord_x]\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.01, 0.001, 0.0001, 0.01, 0.01]) # шаг обучения для каждого параметра w0, w1, w2, w3, w4\n",
    "w = np.array([0., 0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "\n",
    "Qe = np.sum([(np.dot(w, x_train[i]) - coord_y[i]) ** 2 for i in range(sz)]) / sz # начальное значение среднего эмпирического риска\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, sz)\n",
    "    x_k = x_train[k]\n",
    "    y_k = coord_y[k]\n",
    "    loss_func = (np.dot(w, x_k) - y_k) ** 2 \n",
    "    # SGD step\n",
    "    diff_lf = 2 * np.dot((np.dot(w, x_k) - y_k), x_k) # lf - loss function\n",
    "    w = w - eta * diff_lf\n",
    "    # Qe recalculation\n",
    "    Qe = lm * loss_func + (1 - lm) * Qe\n",
    "\n",
    "Q = np.sum([(np.dot(w, x_train[i]) - coord_y[i]) ** 2 for i in range(sz)]) / sz\n",
    "print(Q)\n",
    "print(Qe)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d7eb8",
   "metadata": {},
   "source": [
    "# Same task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0587b9",
   "metadata": {},
   "source": [
    "<img src=\".././photo/condition6.png\" alt=\"photo\" width=\"672\" height=\"336\">\n",
    "<img src=\".././photo/condition7.png\" alt=\"photo\" width=\"672\" height=\"336\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99152ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02010989021755196\n",
      "0.020450387266387284\n",
      "[-2.49725214  0.49451654  0.19757031 -0.04967255]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1) # значения по оси абсцисс [-4; 6] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "x_train = [[1, x, x ** 2, x ** 3] for x in coord_x]\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001]) # шаг обучения для каждого параметра w0, w1, w2, w3\n",
    "w = np.array([0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "batch_size = 50 # размер мини-батча (величина K = 50)\n",
    "\n",
    "Qe = np.sum([(np.dot(w, x_train[i]) - coord_y[i]) ** 2 for i in range(batch_size)]) / (batch_size) # начальное значение среднего эмпирического риска\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел \n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, sz - batch_size)\n",
    "    arr_x_k = [x_train[j] for j in range(k, k + batch_size)]\n",
    "    arr_y_k = [coord_y[j] for j in range(k, k + batch_size)]\n",
    "\n",
    "    Qk = np.sum([(np.dot(w, x) - y) ** 2 for x, y in zip(arr_x_k, arr_y_k)]) / batch_size\n",
    "\n",
    "    # it's (np.dot(w, x) - y) - a scalar, x - vector, if i use np.outer, x will be the vector (1, 4), but i need (4,) like following (np.array(x))\n",
    "    diff_Qk = 2 * np.sum([(np.dot(w, x) - y) * np.array(x) for x, y in zip(arr_x_k, arr_y_k)], axis=0) / batch_size\n",
    "    w = w - eta * diff_Qk\n",
    "    \n",
    "    Qe = lm * Qk + (1 - lm) * Qe\n",
    "\n",
    "Q = np.sum([(np.dot(w, x_train[i]) - coord_y[i]) ** 2 for i in range(sz)]) / sz\n",
    "print(Q)\n",
    "print(Qe)\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
