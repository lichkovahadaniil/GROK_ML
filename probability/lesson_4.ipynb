{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4ccb7e",
   "metadata": {},
   "source": [
    "# Naive Bayesian classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d3ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathExp (length, width) for class \"1\":  35.0 31.0\n",
      "MathExp (length, width) for class \"-1\":  52.0 14.4\n",
      "Variance by selection (length, width) for class \"1\":  80.0 50.0\n",
      "Variance by selection (length, width) for class \"-1\":  34.3 182.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[10, 50], [20, 30], [25, 30], [20, 60], [15, 70], [40, 40], [30, 45], [20, 45], [40, 30], [7, 35]])\n",
    "y_train = np.array([-1, 1, 1, -1, -1, 1, 1, -1, 1, -1])\n",
    "\n",
    "# calculate math expectation (_1 == -1)\n",
    "mw1, ml1 = np.mean(x_train[y_train == 1], axis=0)\n",
    "mw_1, ml_1 = np.mean(x_train[y_train == -1], axis=0)\n",
    "\n",
    "# variances by selections\n",
    "sw1, sl1 = np.var(x_train[y_train == 1], axis=0, ddof=1)\n",
    "sw_1, sl_1 = np.var(x_train[y_train == -1], axis=0, ddof=1)\n",
    "\n",
    "print('MathExp (length, width) for class \"1\": ', ml1, mw1)\n",
    "print('MathExp (length, width) for class \"-1\": ', ml_1, mw_1)\n",
    "\n",
    "print('Variance by selection (length, width) for class \"1\": ', sw1, sl1)\n",
    "print('Variance by selection (length, width) for class \"-1\": ', sw_1, sl_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e222fca",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x with width == 10 and length == 40 we classify as -1 (1: ladybug, -1: caterpillar)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "x = [10, 40] # width, length\n",
    "\n",
    "# np.log = ln\n",
    "a_1 = lambda x: -np.log(sw_1 * sl_1) - (x[1] - ml_1) ** 2 / (2 * sl_1) - (x[0] - mw_1) ** 2 / (2 * sw_1)\n",
    "a1 = lambda x: -np.log(sw1 * sl1) - (x[1] - ml1) ** 2 / (2 * sl1) - (x[0] - mw1) ** 2 / (2 * sw1)\n",
    "\n",
    "y = np.argmax([a_1(x), a1(x)]) # take 0 or 1 - indexes in y_train (by first input in y_train-array (=[-1, 1]))\n",
    "print(f'x with width == {x[0]} and length == {x[1]} we classify as {y_train[y]} (1: ladybug, -1: caterpillar)')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ef54d",
   "metadata": {},
   "source": [
    "## Test by train selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640ad0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pr = []\n",
    "for x in x_train:\n",
    "    pr.append(y_train[np.argmax([a_1(x), a1(x)])])\n",
    "pr = np.array(pr)\n",
    "Q = np.mean(pr != y_train) # share of errors\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302abbd",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_x = [(7.2, 2.5), (6.4, 2.2), (6.3, 1.5), (7.7, 2.2), (6.2, 1.8), (5.7, 1.3), (7.1, 2.1), (5.8, 2.4), (5.2, 1.4), (5.9, 1.5), (7.0, 1.4), (6.8, 2.1), (7.2, 1.6), (6.7, 2.4), (6.0, 1.5), (5.1, 1.1), (6.6, 1.3), (6.1, 1.4), (6.7, 2.1), (6.4, 1.8), (5.6, 1.3), (6.9, 2.3), (6.4, 1.9), (6.9, 2.3), (6.5, 2.2), (6.0, 1.5), (5.6, 1.1), (5.6, 1.5), (6.0, 1.0), (6.0, 1.8), (6.7, 2.5), (7.7, 2.3), (5.5, 1.1), (5.8, 1.0), (6.9, 2.1), (6.6, 1.4), (6.3, 1.6), (6.1, 1.4), (5.0, 1.0), (7.7, 2.0), (4.9, 1.7), (7.2, 1.8), (6.8, 1.4), (6.1, 1.2), (5.8, 1.9), (6.3, 2.5), (5.7, 2.0), (6.5, 1.8), (7.6, 2.1), (6.3, 1.5), (6.7, 1.4), (6.4, 2.3), (6.2, 2.3), (6.3, 1.9), (5.5, 1.3), (7.9, 2.0), (6.7, 1.8), (6.4, 1.3), (6.5, 2.0), (6.5, 1.5), (6.9, 1.5), (5.6, 1.3), (5.8, 1.2), (6.7, 2.3), (6.0, 1.6), (5.7, 1.2), (5.7, 1.0), (5.5, 1.0), (6.1, 1.4), (6.3, 1.8), (5.7, 1.3), (6.1, 1.3), (5.5, 1.3), (6.3, 1.3), (5.9, 1.8), (7.7, 2.3), (6.5, 2.0), (5.6, 2.0), (6.7, 1.7), (5.7, 1.3), (5.5, 1.2), (5.0, 1.0), (5.8, 1.9), (6.2, 1.3), (6.2, 1.5), (6.3, 2.4), (6.4, 1.5), (7.4, 1.9), (6.8, 2.3), (5.6, 1.3), (5.8, 1.2), (7.3, 1.8), (6.7, 1.5), (6.3, 1.8), (6.0, 1.6), (6.4, 2.1), (6.1, 1.8), (5.9, 1.8), (5.4, 1.5), (4.9, 1.0)]\n",
    "data_y = [1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1]\n",
    "\n",
    "x_train = np.array(data_x)\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "# математические ожидания\n",
    "mx11, mx12 = np.mean(x_train[y_train == -1], axis=0)\n",
    "mx21, mx22 = np.mean(x_train[y_train == 1], axis=0)\n",
    "\n",
    "# дисперсии\n",
    "Dx11, Dx12 = np.var(x_train[y_train == -1], axis=0)\n",
    "Dx21, Dx22 = np.var(x_train[y_train == 1], axis=0)\n",
    "\n",
    "lm1 = 1     # штраф неверной классификации 1-го класса (-1)\n",
    "lm2 = 1     # штраф неверной классификации 2-го класса (+1)\n",
    "P1 = 0.5    # априорная вероятность появления образов 1-го класса\n",
    "P2 = 1 - P1 # априорная вероятность появления образов 2-го класса\n",
    "\n",
    "a_1 = lambda x: np.log(lm1 * P1) - np.log(2 * np.pi * Dx11 * Dx12) - (x[0] - mx11) ** 2 / (2 * Dx11) - (x[1] - mx12) ** 2 / (2 * Dx12)\n",
    "a1 = lambda x: np.log(lm2 * P2) - np.log(2 * np.pi * Dx21 * Dx22) - (x[0] - mx21) ** 2 / (2 * Dx21) - (x[1] - mx22) ** 2 / (2 * Dx22)\n",
    "\n",
    "predict = []\n",
    "classes = [-1, 1] # in np.argmax([a_1(x), a1(x)]) class -1 first (a_1(x)), second is +1 (a1(x)), in 'classes' i did same [-1, 1]\n",
    "for x in x_train:  \n",
    "    ind = np.argmax([a_1(x), a1(x)])\n",
    "    predict.append(classes[ind]) # -1 or 1 (we get 0 or 1)\n",
    "\n",
    "predict = np.array(predict)\n",
    "Q = np.mean(predict != y_train)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f30282",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b9f9e",
   "metadata": {},
   "source": [
    "Bayes' theorem can be used to solve not only classification problems, but also regression problems. Let there be a function of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585362d",
   "metadata": {},
   "source": [
    "but in fact use the method of the smallest squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e930e0d",
   "metadata": {},
   "source": [
    "# <img src=\".././photo/condition19.png\" alt=\"photo\" width=\"672\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.49213311  0.50342222  0.19781693 -0.04986103]\n",
      "0.019662942949529676\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "def model(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * x ** 2 + w[3] * x ** 3\n",
    "\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "\n",
    "x_train = np.array([[_x**i for i in range(4)] for _x in coord_x]) # обучающая выборка\n",
    "y_train = func(coord_x) # целевые выходные значения\n",
    "\n",
    "'''\n",
    "w.T has dim (1 * 4)\n",
    "sum(y_i * x_i.T) = sum((w.T * x_i) * x_i.T)\n",
    "sum(y_i * x_i.T) has dimension (1 * 4) -> \n",
    "(X == x_train)\n",
    "X = column with x_i.T-rows -> X has dim (n * 4) ->\n",
    "-> y has dim (n * 1) -> y.T has dim (4 * 1) -> \n",
    "y.T @ X has dim (1 * n) @ (n * 4) = (1 * 4)\n",
    "\n",
    "same with sum((w.T * x_i) * x_i.T), w.T doesn't depend on i-indexes ->\n",
    "w.T @ sum(x_i * x_i.T)\n",
    "x_i has dimension(4 * 1), x_i.T = (1 * 4)\n",
    "x_i @ x_i.T = (4 * 4)\n",
    "X.T @ X = (4 * n) @ (n * 4)\n",
    "x_i * x_i.T = X.T @ X ->\n",
    "-> y.T @ X = w.T @ (X.T @ X) ->\n",
    "w.T = (y.T @ X) @ (X.T @ X)^(-1) = (1 * 4) @ ((4 * n) @ (n * 4))^(-1) = (1 * 4)\n",
    "'''\n",
    "\n",
    "w = y_train.T @ x_train @ np.linalg.inv(x_train.T @ x_train)\n",
    "\n",
    "Q = np.mean([(func(x) - model(w, x)) ** 2 for x in coord_x])\n",
    "\n",
    "print(w)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db438f43",
   "metadata": {},
   "source": [
    "# <img src=\".././photo/s3.png\" alt=\"photo\" width=\"672\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62f2ab",
   "metadata": {},
   "source": [
    "взяли от этого логарифма производную и приравняли к 0, то есть, эквивалентно, нашли градиент по вектору параметров и приравняли к 0 чтобы "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82d818",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
