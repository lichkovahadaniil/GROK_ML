{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ab32e4",
   "metadata": {},
   "source": [
    "# An example of Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd3a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.64395250e+00  1.56201803e-02 -9.97312151e-02 -1.34398923e-02\n",
      "  4.97916283e-03]\n",
      "0.19259504328669183\n",
      "0.26996828082653473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# исходная функция, которую нужно аппроксимировать моделью a(x)\n",
    "def func(x):\n",
    "    return 0.02 * np.exp(-x) - 0.2 * np.sin(3 * x) + 0.5 * np.cos(2 * x) - 7\n",
    "\n",
    "def loss(x, w):\n",
    "    x_vec = np.array([1, x, x**2, x**3, x**4])\n",
    "    return (np.dot(w, x_vec) - func(x)) ** 2\n",
    "\n",
    "def diff_loss(x, w):\n",
    "    x_vec = np.array([1, x, x**2, x**3, x**4])\n",
    "    return 2 * (w.T @ x_vec - func(x)) * x_vec.T\n",
    "\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1) # значения по оси абсцисс [-5; 5] с шагом 0.1\n",
    "coord_y = func(coord_x) # значения функции по оси ординат\n",
    "\n",
    "sz = len(coord_x)\t# количество значений функций (точек)\n",
    "eta = np.array([0.01, 1e-3, 1e-4, 1e-5, 1e-6]) # шаг обучения для каждого параметра w0, w1, w2, w3, w4\n",
    "w = np.array([0., 0., 0., 0., 0.]) # начальные значения параметров модели\n",
    "N = 500 # число итераций алгоритма SGD\n",
    "lm = 0.02 # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "\n",
    "Qe = loss(coord_x[0], w) # начальное значение среднего эмпирического риска (start like a loss-function)\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, sz-1)\n",
    "    w -= eta * diff_loss(coord_x[k], w)\n",
    "\n",
    "    Qe = lm * loss(coord_x[k], w) + (1 - lm) * Qe\n",
    "\n",
    "Q = np.mean([loss(x, w) for x in coord_x])\n",
    "\n",
    "print(w)\n",
    "print(Qe)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb997d20",
   "metadata": {},
   "source": [
    "# Same, but with a mini-batch instead of one random item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda6c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.19963529  0.04245181  4.06445484]\n",
      "0.5406024504857126\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# сигмоидная функция потерь\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return 2 / (1 + np.exp(M))\n",
    "\n",
    "\n",
    "# производная сигмоидной функции потерь по вектору w\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -2 * np.exp(M) * x.T * y / (1 + np.exp(M)) ** 2\n",
    "\n",
    "\n",
    "data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]\n",
    "data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)  # размер обучающей выборки\n",
    "w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты\n",
    "nt = np.array([1, 0.1, 0.1])  # шаг обучения для каждого параметра w0, w1, w2\n",
    "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
    "N = 500  # число итераций алгоритма SGD\n",
    "batch_size = 10 # размер мини-батча (величина K = 10)\n",
    "\n",
    "Qe = np.mean([loss(w, x, y) for x, y in zip(x_train[:batch_size], y_train[:batch_size])]) # начальное значение среднего эмпирического риска\n",
    "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
    "\n",
    "for _ in range(N):\n",
    "    k = np.random.randint(0, n_train - batch_size - 1)\n",
    "    Qk = 0\n",
    "    diff_Qk = []\n",
    "    for i in range(k, k + batch_size):\n",
    "        Qk += loss(w, x_train[i], y_train[i])\n",
    "        diff_Qk.append(df(w, x_train[i], y_train[i]))\n",
    "\n",
    "    Qk /= batch_size\n",
    "    diff_Qk = np.mean(diff_Qk, axis=0)\n",
    "    w -= nt * diff_Qk\n",
    "    Qe = lm * Qk + (1 - lm) * Qe\n",
    "\n",
    "Q = sum([np.dot(w, x) * y < 0 for x, y in zip(x_train, y_train)])\n",
    "\n",
    "print(w)\n",
    "print(Qe)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba98d2",
   "metadata": {},
   "source": [
    "Why is it needed Qe?\n",
    "\n",
    "Qe - monitoring, building a curve so that the trend is visible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
